{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VciyS7I5WuUi",
        "outputId": "c063a71c-56a1-45d1-c01c-98088fc30ca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Using cached torch-2.4.1-cp312-none-macosx_11_0_arm64.whl.metadata (26 kB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.9.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (11 kB)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.1.1-cp312-cp312-macosx_14_0_arm64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm\n",
            "  Using cached tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
            "Collecting filelock (from torch)\n",
            "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.8.0 (from torch)\n",
            "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting sympy (from torch)\n",
            "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting networkx (from torch)\n",
            "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
            "Collecting jinja2 (from torch)\n",
            "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting fsspec (from torch)\n",
            "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting setuptools (from torch)\n",
            "  Using cached setuptools-75.1.0-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.54.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (163 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.7/163.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.7-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/eminarslan/Developer/cs5787/.venv/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Using cached pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.2 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Using cached pyparsing-3.1.4-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/eminarslan/Developer/cs5787/.venv/lib/python3.12/site-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/eminarslan/Developer/cs5787/.venv/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
            "  Using cached MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl.metadata (3.0 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Using cached torch-2.4.1-cp312-none-macosx_11_0_arm64.whl (62.1 MB)\n",
            "Downloading matplotlib-3.9.2-cp312-cp312-macosx_11_0_arm64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.1.1-cp312-cp312-macosx_14_0_arm64.whl (5.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hUsing cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "Downloading contourpy-1.3.0-cp312-cp312-macosx_11_0_arm64.whl (251 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.5/251.5 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.54.1-cp312-cp312-macosx_11_0_arm64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading kiwisolver-1.4.7-cp312-cp312-macosx_11_0_arm64.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl (3.4 MB)\n",
            "Using cached pyparsing-3.1.4-py3-none-any.whl (104 kB)\n",
            "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
            "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
            "Using cached setuptools-75.1.0-py3-none-any.whl (1.2 MB)\n",
            "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "Using cached MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl (18 kB)\n",
            "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Installing collected packages: mpmath, typing-extensions, tqdm, sympy, setuptools, pyparsing, pillow, numpy, networkx, MarkupSafe, kiwisolver, fsspec, fonttools, filelock, cycler, jinja2, contourpy, torch, matplotlib\n",
            "Successfully installed MarkupSafe-2.1.5 contourpy-1.3.0 cycler-0.12.1 filelock-3.16.1 fonttools-4.54.1 fsspec-2024.9.0 jinja2-3.1.4 kiwisolver-1.4.7 matplotlib-3.9.2 mpmath-1.3.0 networkx-3.3 numpy-2.1.1 pillow-10.4.0 pyparsing-3.1.4 setuptools-75.1.0 sympy-1.13.3 torch-2.4.1 tqdm-4.66.5 typing-extensions-4.12.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install torch matplotlib numpy tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-ubIUn_ZW9C0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Matplotlib is building the font cache; this may take a moment.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkD9xlZ2XWwU",
        "outputId": "b2be25c5-dbb9-4c9b-b466-88dd8e31f1bb"
      },
      "outputs": [],
      "source": [
        "seed = 123\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MphAooRPGNQO",
        "outputId": "ebf70efc-6a37-4657-d5a0-4e23f9ed4990"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvThrVOeXtYw",
        "outputId": "80b0d077-d4b2-4a96-a19f-63a2e402fbfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(array([9983, 2140,  150, 3327, 3300, 3109, 1683, 2266, 8868, 7117, 4775,\n",
              "         1982, 7780, 9959, 9064, 9411,  545, 4534, 8760, 5053, 7647, 4453,\n",
              "         9199, 7319], dtype=int32),\n",
              "  array([2140,  150, 3327, 3300, 3109, 1683, 2266, 8868, 7117, 4775, 1982,\n",
              "         7780, 9959, 9064, 9411,  545, 4534, 8760, 5053, 7647, 4453, 9199,\n",
              "         7319,   66], dtype=int32))]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from zipfile import ZipFile\n",
        "\n",
        "class PTB(Dataset):\n",
        "    def __init__(self, root_dir, which):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            root_dir (string): Directory containing the data files.\n",
        "            which (string): \"train\", \"test\", or \"val\" dataset\n",
        "        \"\"\"\n",
        "        d = {\"train\": 1, \"test\": 5, \"val\": 7}\n",
        "        with ZipFile(root_dir, 'r') as zip_ref:\n",
        "            file_name = zip_ref.namelist()[d[which]]\n",
        "            with zip_ref.open(file_name) as file:\n",
        "                content = file.read().decode('utf-8')\n",
        "                words = content.split()\n",
        "                self.index_to_word = {idx: word for idx, word in enumerate(set(words))}\n",
        "                self.word_to_index = {word: idx for idx, word in enumerate(set(words))}\n",
        "                self.data = np.array([self.word_to_index[word] for word in words], dtype=np.int32)\n",
        "        self.sequence_length = 24\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # deal with slices\n",
        "        if isinstance(idx, slice):\n",
        "          return [self[i] for i in range(*idx.indices(len(self)))]\n",
        "\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.item()\n",
        "\n",
        "        idx = idx % (len(self.data) - self.sequence_length)\n",
        "        sequence = self.data[idx:idx + self.sequence_length]\n",
        "        target = self.data[idx + 1:idx + self.sequence_length + 1]\n",
        "        return sequence, target\n",
        "\n",
        "\n",
        "train_set = PTB(root_dir='./ptb_data.zip', which='train')\n",
        "test_set = PTB(root_dir='./ptb_data.zip', which='test')\n",
        "val_set = PTB(root_dir='./ptb_data.zip', which='val')\n",
        "\n",
        "x = train_set[:1]\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kF41IM8AkooH"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 20\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=batch_size)#, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=batch_size)#, shuffle=True)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size)#, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIf6MOcEk3Fr",
        "outputId": "09f7818f-0697-4109-e8f1-690e35ce53c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20, 24]) torch.Size([20, 24])\n"
          ]
        }
      ],
      "source": [
        "for text, pred in train_loader:\n",
        "  print(text.shape, pred.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_QuaPshqlWKO",
        "outputId": "16dd8972-b688-49e6-cdfe-23f24634b6fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LSTM(\n",
            "  (embedding): Embedding(9999, 64)\n",
            "  (lstm): LSTM(64, 200, num_layers=2, batch_first=True)\n",
            "  (linear): Linear(in_features=200, out_features=9999, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=2, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeds = self.embedding(x)\n",
        "        out, _ = self.lstm(embeds)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "net = LSTM(64, 200, len(train_set.index_to_word))\n",
        "net.to(device)\n",
        "print(net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE2fdQiLWvfz",
        "outputId": "2c82eff9-ac76-41e2-db6a-bf2ac2e440d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LSTM(\n",
              "  (lstm): LSTM(9999, 200, num_layers=2)\n",
              "  (linear): Linear(in_features=200, out_features=9999, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from torch.nn import functional as F\n",
        "\n",
        "# class LSTM(nn.Module):\n",
        "#     def __init__(self, hidden_dim, vocab_size):\n",
        "#         super().__init__()\n",
        "#         self.lstm = nn.LSTM(vocab_size, hidden_dim, num_layers=2)\n",
        "#         self.linear = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         out, _ = self.lstm(F.one_hot(x.long(), num_classes=len(train_set.index_to_word)).float())\n",
        "#         out = self.linear(out.view(len(out), -1))\n",
        "#         return out\n",
        "\n",
        "# net = LSTM(200, len(train_set.index_to_word))\n",
        "# net.to(\"cuda\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IEpG9ncgmO8T",
        "outputId": "1a2ecde5-4767-4f3c-c26d-475ae7348448"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([20, 24]) torch.Size([20, 24])\n",
            "torch.Size([20, 24, 9999])\n"
          ]
        }
      ],
      "source": [
        "for text, pred in train_loader:\n",
        "  text = text.to(device)\n",
        "  pred = pred.to(device)\n",
        "  print(text.shape, pred.shape)\n",
        "  outputs = net(text)\n",
        "  print(outputs.shape)\n",
        "  break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "WJvXbnxuno0o"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def train(model, train_loader, val_loader, loss_fn, optimizer, epochs=10):\n",
        "  try:\n",
        "    # for epoch in tqdm(range(epochs)):\n",
        "    for epoch in range(epochs):\n",
        "      model.train()\n",
        "      print(f\"Epoch: {epoch}\")\n",
        "      total_loss = 0\n",
        "      count = 0\n",
        "      for text, pred in train_loader:\n",
        "        text = text.to(device)\n",
        "        pred = pred.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(text)\n",
        "        # loss = loss_fn(outputs, pred.long())\n",
        "        loss = loss_fn(outputs.view(-1, outputs.size(-1)), pred.view(-1).long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        count += 1\n",
        "      print(f\"Train Loss: {total_loss / count}\")\n",
        "      perplexity = torch.exp(torch.tensor(total_loss / len(train_loader)))\n",
        "      print(f\"Perplexity: {perplexity}\")\n",
        "      model.eval()\n",
        "      with torch.no_grad():\n",
        "        total_loss = 0\n",
        "        count = 0\n",
        "        for text, pred in val_loader:\n",
        "          text = text.to(device)\n",
        "          pred = pred.to(device)\n",
        "          outputs = net(text)\n",
        "          # loss = loss_fn(outputs, pred.long())\n",
        "          loss = loss_fn(outputs.view(-1, outputs.size(-1)), pred.view(-1).long())\n",
        "          total_loss += loss.item()\n",
        "          count += 1\n",
        "        print(f\"Val Loss: {total_loss / count}\")\n",
        "        perplexity = torch.exp(torch.tensor(total_loss / batch_size))\n",
        "        print(f\"Perplexity: {perplexity}\")\n",
        "  except KeyboardInterrupt:\n",
        "    print(\"Exiting...\")\n",
        "\n",
        "def test(model, test_loader, loss_fn):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for text, pred in test_loader:\n",
        "      text = text.to(device)\n",
        "      pred = pred.to(device)\n",
        "      outputs = net(text)\n",
        "      total_loss += loss_fn(outputs.view(-1, outputs.size(-1)), pred.view(-1).long())\n",
        "    perplexity = torch.exp(torch.tensor(total_loss / batch_size))\n",
        "    print(f\"Perplexity: {perplexity}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJWKjALwlrU3",
        "outputId": "40810813-98b7-4df1-d4f6-82c7418cbefd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3520"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(val_loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "21b681fcd05942818c19fa202296112b",
            "1935b8270ac143e290a465c76e8105d2",
            "8f73bd36c7b04cd1af3a9402e3726de7",
            "f90cbbcd6d984a4babf8f9625580b01b",
            "ffcbd003a7a0479d99fa253dec5b2a72",
            "f76b3181ebcf442195eb310094cdeb82",
            "02c5372be8314006a827401582a84800",
            "95157ca3925b46f584ef775ad66f28fe",
            "b908dd94b53e45c6bf4c958beec49752",
            "a7034044a2dd4913acb8a7d587c99f7e",
            "f927e1c754254ee7a9d23cb596f9db0e"
          ]
        },
        "id": "pcs-edIzougN",
        "outputId": "a56333ea-4701-4fc9-c55b-b55dab0f51ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0\n",
            "Exiting...\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "cannot unpack non-iterable NoneType object",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m loss_fn \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(net\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m net_acc, net_test_acc \u001b[38;5;241m=\u001b[39m train(net, train_loader, val_loader, loss_fn, optimizer, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ],
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=1)\n",
        "net_acc, net_test_acc = train(net, train_loader, val_loader, loss_fn, optimizer, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMMRsMeqpKHC",
        "outputId": "69264776-8a92-4b90-a0c9-0fbc2abc2262"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Perplexity: 255238.828125\n"
          ]
        }
      ],
      "source": [
        "test(net, test_loader)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02c5372be8314006a827401582a84800": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1935b8270ac143e290a465c76e8105d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f76b3181ebcf442195eb310094cdeb82",
            "placeholder": "​",
            "style": "IPY_MODEL_02c5372be8314006a827401582a84800",
            "value": " 10%"
          }
        },
        "21b681fcd05942818c19fa202296112b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1935b8270ac143e290a465c76e8105d2",
              "IPY_MODEL_8f73bd36c7b04cd1af3a9402e3726de7",
              "IPY_MODEL_f90cbbcd6d984a4babf8f9625580b01b"
            ],
            "layout": "IPY_MODEL_ffcbd003a7a0479d99fa253dec5b2a72"
          }
        },
        "8f73bd36c7b04cd1af3a9402e3726de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95157ca3925b46f584ef775ad66f28fe",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b908dd94b53e45c6bf4c958beec49752",
            "value": 1
          }
        },
        "95157ca3925b46f584ef775ad66f28fe": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7034044a2dd4913acb8a7d587c99f7e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b908dd94b53e45c6bf4c958beec49752": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f76b3181ebcf442195eb310094cdeb82": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f90cbbcd6d984a4babf8f9625580b01b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7034044a2dd4913acb8a7d587c99f7e",
            "placeholder": "​",
            "style": "IPY_MODEL_f927e1c754254ee7a9d23cb596f9db0e",
            "value": " 1/10 [03:58&lt;35:48, 238.69s/it]"
          }
        },
        "f927e1c754254ee7a9d23cb596f9db0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ffcbd003a7a0479d99fa253dec5b2a72": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
